# Advanced RAG

An advanced Retrieval-Augmented Generation (RAG) system for processing and querying books in PDF and EPUB formats using LangGraph, with adaptive query rewriting and web search fallback.

## ğŸ—ï¸ Project Structure

```
advanced-rag/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ ingest/
â”‚       â”œâ”€â”€ loaders.py          # Document loaders for PDF and EPUB
â”‚       â””â”€â”€ chunking.py         # Text chunking utilities
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py               # Environment configuration
â”‚   â”œâ”€â”€ state.py                # Graph state definition
â”‚   â”œâ”€â”€ chains.py               # LLM chains (grader, generator, rewriter)
â”‚   â”œâ”€â”€ tools.py                # External tools (web search)
â”‚   â”œâ”€â”€ retriever.py            # Vector store and retriever setup
â”‚   â””â”€â”€ graph/
â”‚       â”œâ”€â”€ nodes.py            # LangGraph node functions
â”‚       â””â”€â”€ app.py              # Graph compilation and workflow
â”œâ”€â”€ data/
â”‚   â””â”€â”€ books/                  # Book files (PDF, EPUB)
â”œâ”€â”€ main.ipynb                  # Jupyter notebook for experimentation
â”œâ”€â”€ run.py                      # Main entry point
â”œâ”€â”€ pyproject.toml              # Project dependencies
â””â”€â”€ README.md
```

## ğŸš€ Features

- **Document Processing**: Load and process PDF and EPUB files
- **Intelligent Chunking**: Split documents using tiktoken-based text splitter
- **Semantic Search**: Vector-based retrieval using ChromaDB and OpenAI embeddings
- **Document Grading**: LLM-powered relevance scoring for retrieved documents
- **Adaptive Query**: Automatically rewrites queries for better web search results
- **Web Search Fallback**: Uses Tavily API when retrieved documents are insufficient
- **LangGraph Workflow**: Structured, debuggable multi-step RAG pipeline

## ğŸ“¦ Installation

1. **Clone the repository**:
   ```bash
   cd advanced-rag
   ```

2. **Install dependencies with uv**:
   ```bash
   uv sync
   ```

3. **Set up environment variables**:
   ```bash
   export OPENAI_API_KEY="your-openai-api-key"
   export TAVILY_API_KEY="your-tavily-api-key"
   ```

## ğŸ¯ Usage

### Run the full RAG pipeline:

```bash
uv run python run.py
```

### Use in Jupyter Notebook:

```bash
jupyter notebook main.ipynb
```

### Programmatic usage:

```python
from src.config import setup_environment
from src.graph.app import app

# Setup environment
setup_environment()

# Run query
inputs = {"question": "What is the future of AI Engineering?"}
for output in app.stream(inputs):
    print(output)
```

## ğŸ”§ How It Works

The RAG system follows this workflow:

1. **Retrieve**: Fetch relevant documents from vector store
2. **Grade**: Score documents for relevance to the question
3. **Decision**: 
   - If documents are relevant â†’ Generate answer
   - If documents are not relevant â†’ Transform query
4. **Transform Query** (if needed): Rewrite question for web search
5. **Web Search** (if needed): Fetch additional context from web
6. **Generate**: Create final answer using retrieved context

## ğŸ“š Adding Books

Place your PDF or EPUB files in the `data/books/` directory. The system will automatically load and process them.

## ğŸ› ï¸ Development

### Install dev dependencies:

```bash
uv sync --dev
```

### Format code:

```bash
uv run black .
```

### Lint code:

```bash
uv run ruff check .
```

## ğŸ“ Dependencies

- **LangChain**: LLM orchestration and chains
- **LangGraph**: Workflow and state management
- **OpenAI**: LLM and embeddings
- **ChromaDB**: Vector storage
- **Tavily**: Web search API
- **tiktoken**: Token counting and chunking

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

MIT License

